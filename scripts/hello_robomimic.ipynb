{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad2d23c",
   "metadata": {},
   "source": [
    "## 1. Getting Started\n",
    "\n",
    "[Doc: getting started](https://robomimic.github.io/docs/introduction/getting_started.html)\n",
    "To use tensorboard, run\n",
    "```bash\n",
    "tensorboard --logdir bc_trained_models/test --host 127.0.0.1 --port 6006\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfb1de",
   "metadata": {},
   "source": [
    "### 1.1. Off-screen renderer test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1903e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Off-screen renderer test\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import robosuite as suite\n",
    "from robomimic.envs.env_robosuite import EnvRobosuite\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"egl\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
    "os.environ[\"MUJOCO_EGL_DEVICE_ID\"] = os.environ.get(\"MUJOCO_EGL_DEVICE_ID\", \"0\")\n",
    "\n",
    "def test_robosuite_offscreen_render():\n",
    "    env = suite.make(\n",
    "        env_name=\"Lift\",\n",
    "        robots=\"Panda\",\n",
    "        has_renderer=False,              # no onscreen window\n",
    "        has_offscreen_renderer=True,     # we want rgb_array frames\n",
    "        use_camera_obs=False,\n",
    "        control_freq=20,\n",
    "    )\n",
    "    env.reset()\n",
    "    frame = env.sim.render(height=256, width=256, camera_name=\"frontview\")\n",
    "\n",
    "    plt.imshow(frame); plt.show()\n",
    "    print(\"\\tframe dtype/shape:\", frame.dtype, frame.shape)\n",
    "    print(\"\\tframe min/max:\", np.min(frame), np.max(frame))\n",
    "    print(\"\\t✅ robosuite render OK\")\n",
    "    \n",
    "def test_robomimic_offscreen_render():\n",
    "    \n",
    "    ObsUtils.initialize_obs_utils_with_obs_specs({\n",
    "        \"obs\":  {\"low_dim\": [], \"rgb\": [], \"depth\": [], \"scan\": []},\n",
    "        \"goal\": {\"low_dim\": [], \"rgb\": [], \"depth\": [], \"scan\": []},\n",
    "    })\n",
    "\n",
    "    \n",
    "    env = EnvRobosuite(\n",
    "        env_name=\"Lift\",\n",
    "        robots=\"Panda\",\n",
    "        render=False,          # no onscreen\n",
    "        render_offscreen=True, # important\n",
    "        use_image_obs=False,\n",
    "    )\n",
    "\n",
    "    env.reset()\n",
    "    img = env.render(mode=\"rgb_array\", height=256, width=256)\n",
    "    plt.imshow(img); plt.show()\n",
    "    print(\"\\trobomimic rgb_array:\", type(img), getattr(img, \"shape\", None), getattr(img, \"dtype\", None))\n",
    "    print(\"\\t✅ robomimic render OK\")\n",
    "\n",
    "test_robosuite_offscreen_render()\n",
    "test_robomimic_offscreen_render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ae962d",
   "metadata": {},
   "source": [
    "### 1.2. Training pipeline sanity check: train_bc_rnn.py (~1.5 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python examples/train_bc_rnn.py --debug\n",
    "import sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve().parent\n",
    "ROBOMIMIC_CWD = REPO_ROOT / \"third_party\" / \"robomimic\"\n",
    "print(f\"robomimic working directory: {ROBOMIMIC_CWD}\")\n",
    "\n",
    "cmd = [sys.executable, str(ROBOMIMIC_CWD / \"examples\" / \"train_bc_rnn.py\"), \n",
    "       \"--debug\"]\n",
    "subprocess.run(cmd, input=\"y\\n\", text=True, check=True, cwd=str(ROBOMIMIC_CWD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78904bce",
   "metadata": {},
   "source": [
    "### 1.3 Actually train a diffusion policy (~15 minutes)\n",
    "\n",
    "This scripts can run for a long time, feel free to terminate it early after a few checkpoints have been saved.\n",
    "\n",
    "Robomimic has an open issue with [rendering diffusion policy rollouts](https://github.com/ARISE-Initiative/robomimic/issues/269).\n",
    "- The current solution is setting `render_video=False` in [exp/templates/diffusion_policy.json](../third_party/robomimic/robomimic/exps/templates/diffusion_policy.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"MUJOCO_GL\"] = \"glx\"\n",
    "os.environ[\"PYOPENGL_PLATFORM\"] = \"glx\"\n",
    "os.environ[\"MUJOCO_EGL_DEVICE_ID\"] = os.environ.get(\"MUJOCO_EGL_DEVICE_ID\", \"0\")\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve().parent\n",
    "ROBOMIMIC_CWD = REPO_ROOT / \"third_party\" / \"robomimic\"\n",
    "\n",
    "print(f\"robomimic working directory: {ROBOMIMIC_CWD}\")\n",
    "assert ROBOMIMIC_CWD.is_dir(), f\"robomimic dir not found: {ROBOMIMIC_CWD}\"\n",
    "\n",
    "# 1) Download datasets (run from robomimic/)\n",
    "cmd = [sys.executable, \"-m\", \"robomimic.scripts.download_datasets\",\n",
    "       \"--tasks\", \"lift\", \"--dataset_types\", \"ph\"]\n",
    "subprocess.run(cmd, input=\"y\\n\",  # automatically pass y to download_datasets.py when propted \"Overwrite?\"\n",
    "               text=True, check=True, cwd=str(ROBOMIMIC_CWD))\n",
    "\n",
    "# 2) Train (run from robomimic/)\n",
    "cmd = [sys.executable, \"-m\", \"robomimic.scripts.train\",\n",
    "       \"--config\", \"robomimic/exps/templates/diffusion_policy.json\",\n",
    "    #    \"--config\", \"robomimic/exps/templates/bc.json\",\n",
    "       \"--dataset\", \"datasets/lift/ph/low_dim_v15.hdf5\"]\n",
    "subprocess.run(cmd, input=\"y\\n\", text=True, check=True, cwd=str(ROBOMIMIC_CWD))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e326e6",
   "metadata": {},
   "source": [
    "## 2. Generate Rollout Policy Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "from IPython.display import display\n",
    "import h5py\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import flax.nnx as nnx # only used here for displaying h5 trees\n",
    "\n",
    "repo_root = Path('../')\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "from robomimic.models.policy_nets import ActorNetwork, GaussianActorNetwork\n",
    "from robomimic.models.diffusion_policy_nets import ConditionalUnet1D\n",
    "\n",
    "from src.latent_sope.robomimic_interface.rollout import (\n",
    "    rollout,\n",
    "    RolloutPolicy,\n",
    "    RolloutLatentRecorder,\n",
    "    RolloutLatentTrajectory,\n",
    "    save_rollout_latents,\n",
    "    get_policy_frame_stack,\n",
    "    PolicyFeatureHook,\n",
    ")\n",
    "from src.latent_sope.robomimic_interface.checkpoints import (\n",
    "    load_checkpoint,\n",
    "    load_demo,\n",
    "    build_h5_tree,\n",
    "    build_algo_from_checkpoint,\n",
    "    build_env_from_checkpoint,\n",
    "    build_rollout_policy_from_checkpoint,\n",
    "    prepare_obs,\n",
    "    EnvBase,\n",
    ")\n",
    "from src.latent_sope.utils.common import CONSOLE_LOGGER\n",
    "\n",
    "dataset_path = Path(\"../third_party/robomimic/datasets/lift/ph/low_dim_v15.hdf5\")\n",
    "# policy_train_dir = Path(\"../third_party/robomimic/bc_trained_models/test/20260119152203\")\n",
    "test_dir = Path(\"../third_party/robomimic/diffusion_policy_trained_models/test\")\n",
    "policy_train_dirs = sorted([d for d in test_dir.glob(\"*\") if d.is_dir()])\n",
    "assert len(policy_train_dirs) > 0, \"No policy train dirs found, you have to train a policy first!\"\n",
    "policy_train_dir = policy_train_dirs[-1]\n",
    "\n",
    "output_video_path = policy_train_dir / \"rollout.mp4\"\n",
    "output_latents_path = policy_train_dir / \"rollout_latents.h5\"\n",
    "demo_index = 0\n",
    "num_steps = 60\n",
    "\n",
    "\"\"\" 1. Load policy and environment from checkpoint \"\"\"\n",
    "policy_model_checkpoint = load_checkpoint(policy_train_dir.resolve(),\n",
    "                                          ckpt_path=\"last.pth\")\n",
    "policy_algo = build_algo_from_checkpoint(policy_model_checkpoint)\n",
    "policy_net: ActorNetwork | ConditionalUnet1D = policy_algo.nets.policy\n",
    "##test\n",
    "keys = list(policy_algo.global_config.all_obs_keys)\n",
    "print(\"policy expects keys (len={}):\".format(len(keys)))\n",
    "print(keys)\n",
    "\n",
    "img_like = [k for k in keys if (\"image\" in k) or (\"rgb\" in k)]\n",
    "print(\"\\nimage-like keys in policy:\", img_like)\n",
    "##test\n",
    "\n",
    "policy:RolloutPolicy = build_rollout_policy_from_checkpoint(policy_model_checkpoint, \n",
    "                                              device=torch.device(\"cuda\"), verbose=False)\n",
    "\n",
    "from robomimic.models.obs_nets import ObservationEncoder\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "##test\n",
    "found = False\n",
    "for name, m in policy_net.named_modules():\n",
    "    if isinstance(m, ObservationEncoder):\n",
    "        found = True\n",
    "        print(\"FOUND ObservationEncoder at:\", name)\n",
    "\n",
    "        enc_keys = list(m.obs_shapes.keys())\n",
    "        print(\"encoder obs keys:\", enc_keys)\n",
    "\n",
    "        rgb_keys = [k for k in enc_keys if ObsUtils.key_is_obs_modality(key=k, obs_modality=\"rgb\")]\n",
    "        print(\"encoder rgb keys:\", rgb_keys)\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(\"No ObservationEncoder found inside policy_net.\")\n",
    "##test\n",
    "import robomimic.utils.tensor_utils as TensorUtils\n",
    "\n",
    "def find_first_obs_encoder(root):\n",
    "    for name, m in root.named_modules():\n",
    "        if isinstance(m, ObservationEncoder):\n",
    "            return name, m\n",
    "    return None, None\n",
    "\n",
    "# ---- A) find the obs encoder inside the REAL torch module used for forward ----\n",
    "# Try policy_net first (usually correct)\n",
    "enc_name, obs_encoder = find_first_obs_encoder(policy_net)\n",
    "print(\"found obs encoder in policy_net:\", enc_name, type(obs_encoder))\n",
    "\n",
    "# If not found / doesn't fire later, we will try to hook inside `policy` (RolloutPolicy wrapper)\n",
    "assert obs_encoder is not None, \"No ObservationEncoder found inside policy_net. This policy may not be vision-based.\"\n",
    "\n",
    "keys = list(obs_encoder.obs_shapes.keys())\n",
    "print(\"encoder obs keys:\", keys)\n",
    "\n",
    "rgb_keys = [k for k in keys if ObsUtils.key_is_obs_modality(k, \"rgb\")]\n",
    "print(\"rgb_keys:\", rgb_keys)\n",
    "assert len(rgb_keys) > 0, \"No rgb keys -> this checkpoint/policy is not using vision (cannot hook visual latent).\"\n",
    "\n",
    "rgb_key = rgb_keys[0]\n",
    "print(\"using rgb_key =\", rgb_key)\n",
    "\n",
    "# ---- B) hook VisualCore output and mirror post-net steps ----\n",
    "class VisualLatentHook:\n",
    "    def __init__(self, obs_encoder, rgb_key, detach=True):\n",
    "        self.obs_encoder = obs_encoder\n",
    "        self.rgb_key = rgb_key\n",
    "        self.detach = detach\n",
    "\n",
    "        self.visual_net = obs_encoder.obs_nets[rgb_key]                 # VisualCore\n",
    "        self.randomizers = list(obs_encoder.obs_randomizers[rgb_key])   # ModuleList\n",
    "        self.activation = obs_encoder.activation                        # ReLU or None\n",
    "\n",
    "        self.latest = None\n",
    "        self.handle = self.visual_net.register_forward_hook(self._hook)\n",
    "\n",
    "        print(\"[VisualLatentHook] hooked net:\", type(self.visual_net), \"for key:\", rgb_key)\n",
    "\n",
    "    def _hook(self, module, inputs, output):\n",
    "        x = output\n",
    "\n",
    "        # same order as ObservationEncoder.forward AFTER obs_nets[k](x)\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "\n",
    "        for rand in reversed(self.randomizers):\n",
    "            if rand is not None:\n",
    "                x = rand.forward_out(x)\n",
    "\n",
    "        x = TensorUtils.flatten(x, begin_axis=1)\n",
    "\n",
    "        if self.detach:\n",
    "            x = x.detach()\n",
    "\n",
    "        self.latest = x\n",
    "\n",
    "    def close(self):\n",
    "        if self.handle is not None:\n",
    "            self.handle.remove()\n",
    "            self.handle = None\n",
    "\n",
    "vis_hook = VisualLatentHook(obs_encoder, rgb_key)\n",
    "\n",
    "env:EnvBase = build_env_from_checkpoint(\n",
    "    policy_model_checkpoint,\n",
    "    render=False,\n",
    "    render_offscreen=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\"\"\" Prepare video writer\"\"\"\n",
    "\n",
    "\n",
    "with h5py.File(dataset_path, \"r\") as h5:\n",
    "    \n",
    "    \"\"\" 2. Load h5 file using h5py and examine the structure \"\"\"\n",
    "    print(\"==== Showing dataset h5 tree (max_depth=2):\")\n",
    "    nnx.display(build_h5_tree(h5, max_depth=2))\n",
    "    print(\"\\n==== Showing data.demo_0 tree: \")\n",
    "    nnx.display(build_h5_tree(h5[\"data\"][\"demo_0\"], max_children=10))\n",
    "    \n",
    "    demo_keys = sorted(list(h5[\"data\"].keys())) # ['demo_0', 'demo_1', 'demo_10', ...]\n",
    "    demo_str_id = demo_keys[demo_keys.index(f\"demo_{demo_index}\")]\n",
    "    obs_keys = sorted(list(h5[\"data\"][demo_str_id][\"obs\"].keys())) # ['object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_eef_quat_site', ...]\n",
    "    \n",
    "    global_cfg_keys = set(policy_algo.global_config.all_obs_keys)\n",
    "    obs_keys = [k for k in obs_keys if k in global_cfg_keys]\n",
    "    obs_keys_visual = [k for k in obs_keys \n",
    "                       if ObsUtils.key_is_obs_modality(key=k, obs_modality=\"rgb\") \n",
    "                       or ObsUtils.key_is_obs_modality(key=k, obs_modality=\"depth\")]\n",
    "    \n",
    "    print(f\"\\n==== obs_keys filtered by global cfg: \")\n",
    "    print(obs_keys)\n",
    "    \n",
    "    obs_np, actions_np = load_demo(h5, demo_str_id, obs_keys, num_steps)\n",
    "    \n",
    "    # obs_stats = policy_model_checkpoint.ckpt_dict.get(\"obs_normalization_stats\", None)\n",
    "    obs_stats = None\n",
    "    obs_torch = prepare_obs(obs_np, device=policy_algo.device, obs_stats=obs_stats)\n",
    "    actions_torch = torch.as_tensor(actions_np, device=policy_algo.device, dtype=torch.float32)\n",
    "    \n",
    "    print(f\"\\n==== Tensors in obs_torch: \")\n",
    "    print(\"\\n\".join([f\"\\t{k}: {v.shape}, {v.device}, {v.dtype}\" for k, v in obs_torch.items()]))\n",
    "    print(f\"\\n==== actions_t: {actions_torch.shape}, {actions_torch.device}, {actions_torch.dtype} \\n\")\n",
    "    \n",
    "    \n",
    "    \"\"\" 3. Build rollout policy \"\"\"\n",
    "    video_writer = imageio.get_writer(str(output_video_path), fps=20)\n",
    "    camera_names = ['agentview']\n",
    "    \n",
    "    frame_stack = get_policy_frame_stack(policy)\n",
    "    feature_hook = PolicyFeatureHook(\n",
    "        policy,\n",
    "        feat_type=\"visual_latent\",\n",
    "    )\n",
    "    print(\"rgb_key:\", getattr(feature_hook, \"_rgb_key\", None))\n",
    "    print(\"visual_net:\", type(getattr(feature_hook, \"_visual_net\", None)))\n",
    "    recorder = RolloutLatentRecorder(\n",
    "        feature_hook,\n",
    "        obs_keys=obs_keys,\n",
    "        store_obs=False,\n",
    "        store_next_obs=False,\n",
    "    )\n",
    "    stats = rollout(\n",
    "        policy=policy,\n",
    "        env=env,\n",
    "        horizon=num_steps,\n",
    "        render=False,\n",
    "        video_writer=video_writer,\n",
    "        video_skip=1,\n",
    "        camera_names=camera_names,\n",
    "        recorder=recorder,\n",
    "    )\n",
    "    video_writer.close()\n",
    "\n",
    "assert vis_hook.latest is not None, \"Hook never fired -> wrong module instance or policy not using rgb.\"\n",
    "print(\"visual latent shape:\", vis_hook.latest.shape)\n",
    "\n",
    "print(f\"==== Rollout video saved at \\n{output_video_path.resolve()}\")\n",
    "\n",
    "traj:RolloutLatentTrajectory = recorder.finalize(stats)\n",
    "#save_rollout_latents(output_latents_path, traj)\n",
    "# -------------------------\n",
    "# Test 0: sanity check that traj.latents is changing over time\n",
    "# -------------------------\n",
    "print(\"traj.latents shape:\", None if traj.latents is None else traj.latents.shape)\n",
    "if traj.latents is not None:\n",
    "    print(\"traj.latents mean/std:\", traj.latents.mean(), traj.latents.std())\n",
    "    d = np.linalg.norm(traj.latents[1:] - traj.latents[:-1], axis=-1)  # (T-1,)\n",
    "    print(\"mean ||Δlatent||:\", d.mean(), \"min:\", d.min(), \"max:\", d.max())\n",
    "\n",
    "save_rollout_latents(output_latents_path, traj)\n",
    "print(f\"==== Saved rollout latents at \\n{output_latents_path.resolve()}\")\n",
    "#print(f\"==== Saved rollout latents at \\n{output_latents_path.resolve()}\")\n",
    "#print(f\"==== Rollout latents traj object:\")\n",
    "nnx.display(traj)\n",
    "\n",
    "#allclose = np.allclose(traj.latents, np.concatenate([traj.obs[k] for k in traj.obs.keys()], axis=-1))\n",
    "#print(\"==== feats @traj.latents stored by @PolicyFeatureHook should be\\n\" +\n",
    "     #f\"     close to feats @traj.obs. Are they? {allclose}\")\n",
    "#assert allclose, \"latents and stacked obs should be close\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# TEST: prove your hook is visual + prove policy uses vision\n",
    "# (NO TRAINING REQUIRED)\n",
    "# ============================\n",
    "import numpy as np\n",
    "\n",
    "# 0) sanity: does policy config expect an image key?\n",
    "keys = list(policy_algo.global_config.all_obs_keys)\n",
    "img_like = [k for k in keys if (\"image\" in k) or (\"rgb\" in k)]\n",
    "print(\"policy expects image-like keys:\", img_like)\n",
    "assert len(img_like) > 0, \"Policy config has no image key -> this checkpoint is likely low-dim only.\"\n",
    "\n",
    "# 1) env reset should return that key\n",
    "obs0 = env.reset()\n",
    "print(\"env.reset keys:\", list(obs0.keys())[:20], \"... total:\", len(obs0.keys()))\n",
    "rgb_key = getattr(feature_hook, \"_rgb_key\", None)  # your PolicyFeatureHook should set this\n",
    "print(\"feature_hook._rgb_key =\", rgb_key)\n",
    "assert rgb_key is not None, \"feature_hook has no _rgb_key (your visual_latent hook setup didn't run).\"\n",
    "assert rgb_key in obs0, f\"env.reset() does not contain rgb_key={rgb_key}. Your env/policy obs keys mismatch.\"\n",
    "\n",
    "# 2) make a perturbed copy of obs0 (only change pixels)\n",
    "obs1 = {k: (v.copy() if hasattr(v, \"copy\") else v) for k, v in obs0.items()}\n",
    "img = obs1[rgb_key].astype(np.float32)\n",
    "noise = np.random.normal(0, 8.0, size=img.shape).astype(np.float32)\n",
    "obs1[rgb_key] = np.clip(img + noise, 0, 255).astype(obs0[rgb_key].dtype)\n",
    "\n",
    "# helper to force one policy forward (works across RolloutPolicy variants)\n",
    "def force_forward(pol, obs):\n",
    "    if hasattr(pol, \"get_action\"):\n",
    "        return pol.get_action(obs)\n",
    "    if callable(pol):\n",
    "        return pol(obs)\n",
    "    if hasattr(pol, \"policy\") and hasattr(pol.policy, \"get_action\"):\n",
    "        return pol.policy.get_action(obs)\n",
    "    raise RuntimeError(\"Can't run policy forward. Inspect policy object methods.\")\n",
    "\n",
    "# 3) run forward on obs0 and obs1 and read the latent that your PolicyFeatureHook captured\n",
    "_ = force_forward(policy, obs0)\n",
    "z0 = feature_hook._last_feature\n",
    "assert z0 is not None, \"Hook didn't fire on obs0 forward (wrong module instance OR policy not using rgb path).\"\n",
    "z0n = z0.detach().float().cpu().numpy()\n",
    "\n",
    "_ = force_forward(policy, obs1)\n",
    "z1 = feature_hook._last_feature\n",
    "assert z1 is not None, \"Hook didn't fire on obs1 forward.\"\n",
    "z1n = z1.detach().float().cpu().numpy()\n",
    "\n",
    "print(\"\\n[HOOK TEST]\")\n",
    "print(\"latent shape:\", z0n.shape)\n",
    "print(\"delta latent L2 :\", float(np.linalg.norm(z1n - z0n)))\n",
    "print(\"delta latent MAE:\", float(np.mean(np.abs(z1n - z0n))))\n",
    "\n",
    "# 4) Optional: prove the ACTION changes when image changes (stronger: policy truly uses vision)\n",
    "a0 = force_forward(policy, obs0)\n",
    "a1 = force_forward(policy, obs1)\n",
    "\n",
    "# a0/a1 might be numpy already or torch; normalize to numpy\n",
    "if hasattr(a0, \"detach\"):\n",
    "    a0 = a0.detach().cpu().numpy()\n",
    "if hasattr(a1, \"detach\"):\n",
    "    a1 = a1.detach().cpu().numpy()\n",
    "a0 = np.asarray(a0)\n",
    "a1 = np.asarray(a1)\n",
    "\n",
    "print(\"\\n[POLICY-USES-VISION TEST]\")\n",
    "print(\"action shape:\", a0.shape)\n",
    "print(\"delta action L2:\", float(np.linalg.norm(a1 - a0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa9d8d2",
   "metadata": {},
   "source": [
    "## 3. Load Policy Rollout Checkpoint and Train Chunk Diffusion Model modules\n",
    "\n",
    "**Policy diffusion:** Implemented in [policy.py](../third_party/sope/opelab/core/policy.py) as `DiffusionPolicy`, which wraps [CleanDiffuser](https://github.com/CleanDiffuserTeam/CleanDiffuser) components (`PearceMlp`, `PearceObsCondition`, `DiscreteDiffusionSDE`) to sample actions from observations.\n",
    "\n",
    "**Trajectory-chunk diffusion (sequence model):** \n",
    "- Implemented in [temporal.py](../third_party/sope/opelab/core/baselines/diffusion/temporal.py) (`TemporalUnet` backbone)\n",
    "- Wrapped by [diffusion.py](../third_party/sope/opelab/core/baselines/diffusion/diffusion.py) (`GaussianDiffusion` sampler)\n",
    "- Used by [diffuser.py](../third_party/sope/opelab/core/baselines/diffuser.py) to generate chunked trajectories.\n",
    "\n",
    "**Guidance link between them:**  During chunked sampling, the trajectory diffusion uses the policy diffusion to compute guidance gradients. \n",
    "- In [diffusion.py](../third_party/sope/opelab/core/baselines/diffusion/diffusion.py), `default_sample_fn(...)` checks the policy type and calls `gradlog_diffusion(...)`\n",
    "- which in turn calls `DiffusionPolicy.grad_log_prob(...)` in [policy.py](../third_party/sope/opelab/core/policy.py) to get a score/grad-log term. \n",
    "- This gradient is scaled and injected into the trajectory diffusion step as the guidance term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import flax.nnx as nnx # only used here for displaying h5 trees\n",
    "\n",
    "repo_root = Path('../')\n",
    "sys.path.append(str(repo_root))\n",
    "\n",
    "from src.latent_sope.utils.common import CONSOLE_LOGGER\n",
    "from src.latent_sope.robomimic_interface.rollout import RolloutLatentTrajectory\n",
    "from src.latent_sope.robomimic_interface.dataset import (\n",
    "    RolloutChunkDatasetConfig,\n",
    "    RolloutChunkDataset,\n",
    "    load_rollout_latents,\n",
    "    make_rollout_chunk_dataloader,\n",
    ")\n",
    "from src.latent_sope.diffusion.ddpm_latents import SopeChunkDiffusionConfig, SopeChunkDiffusion\n",
    "\n",
    "test_dir = Path(\"../third_party/robomimic/diffusion_policy_trained_models/test\")\n",
    "policy_train_dirs = sorted([d for d in test_dir.glob(\"*\") if d.is_dir()])\n",
    "assert len(policy_train_dirs) > 0, \"No policy train dirs found, you have to train a policy first!\"\n",
    "policy_train_dir = policy_train_dirs[-1]\n",
    "\n",
    "rollout_path = policy_train_dir / \"rollout_latents.h5\"\n",
    "assert rollout_path.exists(), f\"Missing rollout file: {rollout_path}. Update the path to a saved rollout.\"\n",
    "\n",
    "dataset_config = RolloutChunkDatasetConfig()\n",
    "data:RolloutLatentTrajectory = load_rollout_latents(rollout_path)\n",
    "dataset:RolloutChunkDataset = RolloutChunkDataset(\n",
    "    traj=data,\n",
    "    config=dataset_config,\n",
    ")\n",
    "\n",
    "item = next(iter(dataset))\n",
    "# frame_stack = 1\n",
    "# obs_dim = data[\"z\"].shape[1] * frame_stack\n",
    "# action_dim = data[\"actions\"].shape[1]\n",
    "\n",
    "# dl, stats = make_rollout_chunk_dataloader(\n",
    "#     paths=[rollout_path],\n",
    "#     W=8,\n",
    "#     stride=1,\n",
    "#     batch_size=4,\n",
    "#     frame_stack=frame_stack,\n",
    "#     source=\"z\",\n",
    "#     include_actions=True,\n",
    "#     normalize=True,\n",
    "# )\n",
    "\n",
    "# batch = next(iter(dl))\n",
    "# if isinstance(batch, (list, tuple)):\n",
    "#     batch = batch[0]\n",
    "\n",
    "# cfg = SopeChunkDiffusionConfig(\n",
    "#     horizon=8,\n",
    "#     obs_dim=obs_dim,\n",
    "#     action_dim=action_dim,\n",
    "#     diffusion_steps=64,\n",
    "# )\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = SopeChunkDiffusion(cfg, normalization_stats=stats, device=device)\n",
    "# opt = model.make_optimizer()\n",
    "\n",
    "# cond = model.make_cond(batch)\n",
    "# loss, _ = model.loss(batch, cond)\n",
    "# loss.backward()\n",
    "# opt.step()\n",
    "# opt.zero_grad()\n",
    "# print(\"loss:\", float(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnx.display(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latent_sope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
